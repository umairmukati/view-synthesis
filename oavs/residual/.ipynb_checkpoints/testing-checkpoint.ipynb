{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload, import_module\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "from PIL import Image as im\n",
    "import _pickle as pickle\n",
    "import cv2\n",
    "\n",
    "from functions import processLF, get_variable, get_numpy, psnr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    dataset_file = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\trainset\\h5\\8bit.h5\"\n",
    "    test_file    = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\testset\\h5\\8bit.h5\"\n",
    "    model_file   = r\"model\\model.pt\"\n",
    "    network_file = r\"network\"\n",
    "    img_dir      = r\"C:\\Users\\mummu\\Documents\\Datasets\\kalantari\\testset\\EXTRA\"\n",
    "    img_paper    = r\"C:\\Users\\mummu\\Documents\\Datasets\\kalantari\\testset\\PAPER\"\n",
    "    \n",
    "elif os.name == 'posix':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 1\n",
    "gamma_val      = 0.4\n",
    "lfsize         = [372, 540, 7, 7]\n",
    "batch_affine   = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToTensor()\n",
    "p = np.ndarray([1])\n",
    "q = np.ndarray([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##converting network to cuda-enabled\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "network_module = import_module(network_file)\n",
    "reload(network_module)\n",
    "\n",
    "Net = network_module.Net\n",
    "\n",
    "net = Net((lfsize[0], lfsize[1]), minibatch_size, lfsize, batchAffine=batch_affine)\n",
    "net.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_file)\n",
    "    \n",
    "    net.load_my_state_dict(checkpoint['model'].state_dict())    \n",
    "    print('Model successfully loaded.')\n",
    "    \n",
    "except:\n",
    "    print('No model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete\n",
    "#result = im.fromarray((get_numpy(corn[0,:3].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner1_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,3:6].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner2_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,6:9].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner3_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,9:].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner4_f.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def single_run(index, img_path = img_paper, img_name = 'Seahorse.png'):\n",
    "            \n",
    "    img = cv2.imread(os.path.join(img_path, img_name))\n",
    "                    \n",
    "    img = processLF(trans(img), lfsize, gamma_val)\n",
    "    \n",
    "    T = img[:, :, index[0], index[1], :].squeeze()\n",
    "    corn = img[:, :, [0, -1, 0, -1], [0, 0, -1, -1], :].squeeze()\n",
    "    \n",
    "    Y, R = synthesizeView(corn, index)\n",
    "\n",
    "    return T, Y, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesizeView(corn, index):\n",
    "                \n",
    "    p[0] = (index[0] - lfsize[2]//2)/(lfsize[2]//2)\n",
    "    q[0] = (index[1] - lfsize[3]//2)/(lfsize[3]//2)\n",
    "    \n",
    "    corn = corn.permute(2,3,0,1).reshape(12,corn.shape[0],corn.shape[1])[None,:]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y, R = net(get_variable(corn), get_variable(torch.from_numpy(p)), get_variable(torch.from_numpy(q)))\n",
    "        \n",
    "    return Y[0].permute(1,2,0), R[0].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bde1a880efba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msingle_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Rock.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gray'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "T, Y, R = single_run([3,3], img_name = 'Rock.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run for all examples in the folder and every perspectives\n",
    "def run_all_examples(img_path):\n",
    "        \n",
    "    files = [file for file in os.listdir(img_path) if file.endswith(\".png\")]\n",
    "    ps = np.ndarray((len(files),7,7))\n",
    "\n",
    "    for fi in range(len(files)):\n",
    "\n",
    "        file = files[fi]\n",
    "\n",
    "        print(\"Current file {}: {}\" .format(fi,file))\n",
    "\n",
    "        img = cv2.imread(os.path.join(img_path, file))\n",
    "        img = processLF(trans(img), lfsize, gamma_val)\n",
    "\n",
    "        corn = img[:, :, [0, -1, 0, -1], [0, 0, -1, -1], :].squeeze()\n",
    "\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "\n",
    "                T = get_numpy(img[:, :, i, j, :])\n",
    "                Y,R,d = synthesizeView(corn, [i, j])\n",
    "                Y = get_numpy(Y)\n",
    "\n",
    "                ps[fi,i,j] = psnr_1(T, Y)\n",
    "        \n",
    "        psnr_excl_corners = ps[fi].reshape(-1)[[i for i in range(49) if (i-np.array((0,6,42,48))).all()]].mean()\n",
    "        \n",
    "        print(\"Current PSNR: {}\" .format(psnr_excl_corners))\n",
    "    \n",
    "    return ps\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps = run_all_examples(img_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision = 2)\n",
    "ps[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=2)\n",
    "# print(ps)\n",
    "\n",
    "#for index, val in enumerate(list)\n",
    "files = [file for file in os.listdir(img_dir) if file.endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _, fi in enumerate(files):\n",
    "ps.reshape(len(files),-1)[:,[i for i in range(49) if (i-np.array((0,6,42,48))).all()]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
