{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload, import_module\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "import pdb\n",
    "import h5py\n",
    "from PIL import Image as im\n",
    "import _pickle as pickle\n",
    "\n",
    "\n",
    "from functions import MyDataset, customTransform, get_variable, get_numpy, compute_gradient, psnr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    dataset_file = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\trainset\\h5\\8bit.h5\"\n",
    "    test_file    = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\testset\\h5\\8bit.h5\"\n",
    "    model_file   = r\"model\\model.pt\"\n",
    "    network_file = r\"network\"\n",
    "    trainwr_file = r\"runs\\train\"\n",
    "    testwr_file  = r\"runs\\test\"\n",
    "elif os.name == 'posix':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size     = 192\n",
    "batch_size     = 300\n",
    "minibatch_size = 10\n",
    "gamma_val      = 0.4\n",
    "lfsize         = [372, 540, 7, 7]\n",
    "num_workers    = 0\n",
    "num_test       = 10\n",
    "num_minibatch  = batch_size//minibatch_size\n",
    "batch_affine   = True\n",
    "num_epochs     = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INITIALIZE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                     transforms.Lambda(customTransform)])\n",
    "\n",
    "train_dataset  = MyDataset(dataset_file, lfsize, data_transform)\n",
    "test_dataset   = MyDataset(test_file, lfsize, data_transform)\n",
    "\n",
    "train_loader   = torch.utils.data.DataLoader(train_dataset, batch_size=minibatch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader    = torch.utils.data.DataLoader(train_dataset, batch_size=minibatch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOKING FOR SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##converting network to cuda-enabled\n",
      "No model.\n"
     ]
    }
   ],
   "source": [
    "network_module = import_module(network_file)\n",
    "reload(network_module)\n",
    "Net = network_module.Net\n",
    "\n",
    "net = Net((patch_size, patch_size), minibatch_size, lfsize, batchAffine=batch_affine)\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_file)\n",
    "    \n",
    "    epoch_id = checkpoint['epoch']\n",
    "    net.load_state_dict(checkpoint['model'].state_dict())\n",
    "    \n",
    "except:\n",
    "    print('No model.')\n",
    "    epoch_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = nn.L1Loss()\n",
    "criterion2 = nn.L1Loss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    costs = []\n",
    "    psnr_vec = []\n",
    "            \n",
    "    for batch_num in range(num_minibatch):\n",
    "        \n",
    "        # fetching training batch\n",
    "        corners, pers, ind = next(iter(train_loader))\n",
    "        \n",
    "        # converting to trainable variables\n",
    "        X_corners = get_variable(corners)\n",
    "        T_view = get_variable(pers)\n",
    "        p = get_variable(ind[:,0])\n",
    "        q = get_variable(ind[:,-1])\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        O_view = net(X_corners, p, q)\n",
    "        \n",
    "        # Computing batch loss\n",
    "        batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view),\n",
    "                                                          compute_gradient(T_view))\n",
    "        \n",
    "        # Backpropagation\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # recording performance\n",
    "        costs.append(get_numpy(batch_loss))\n",
    "        net_out = get_numpy(O_view)\n",
    "        Y = get_numpy(T_view)      \n",
    "        psnr_vec.append([psnr_1(np.squeeze(net_out[i]), np.squeeze(Y[i])) for i in range(minibatch_size)])\n",
    "    \n",
    "        \n",
    "    return np.mean(costs), np.mean(psnr_vec)\n",
    "\n",
    "def eval_epoch():\n",
    "    costs = []\n",
    "    psnr_vec = []\n",
    "    \n",
    "    for batch_num in range(num_test):\n",
    "        \n",
    "        # fetching training batch\n",
    "        corners, pers, ind = next(iter(test_loader))\n",
    "        \n",
    "        # converting to trainable variables\n",
    "        X_corners = get_variable(corners)\n",
    "        T_view = get_variable(pers)\n",
    "        p = get_variable(ind[:,0])\n",
    "        q = get_variable(ind[:,-1])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            O_view = net(X_corners, p, q)\n",
    "            \n",
    "            # Computing batch loss\n",
    "            batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view), compute_gradient(T_view))\n",
    "            \n",
    "            # recording performance\n",
    "            costs.append(get_numpy(batch_loss))\n",
    "            net_out = get_numpy(O_view)\n",
    "            Y = get_numpy(T_view)\n",
    "            psnr_vec.append([psnr_1(np.squeeze(net_out[i]), np.squeeze(Y[i])) for i in range(minibatch_size)])\n",
    "\n",
    "    return np.mean(costs), np.mean(psnr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Epoch 1, train_cost 0.17, psnr 2.6e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "Epoch 2, train_cost 0.13, psnr 2.9e+01\n",
      "Epoch 3:\n",
      "Epoch 3, train_cost 0.12, psnr 2.9e+01\n",
      "Epoch 4:\n",
      "Epoch 4, train_cost 0.12, psnr 3e+01\n",
      "Epoch 5:\n",
      "Epoch 5, train_cost 0.12, psnr 3e+01\n",
      "Epoch 6:\n",
      "Epoch 6, train_cost 0.11, psnr 3e+01\n",
      "Epoch 7:\n",
      "Epoch 7, train_cost 0.11, psnr 3.1e+01\n",
      "Epoch 8:\n",
      "Epoch 8, train_cost 0.1, psnr 3.1e+01\n",
      "Epoch 9:\n",
      "Epoch 9, train_cost 0.11, psnr 3.1e+01\n",
      "Epoch 10:\n",
      "Epoch 10, train_cost 0.11, psnr 3.1e+01\n",
      "Epoch 11:\n",
      "Epoch 11, train_cost 0.11, psnr 3e+01\n",
      "Epoch 12:\n",
      "Epoch 12, train_cost 0.1, psnr 3.1e+01\n"
     ]
    }
   ],
   "source": [
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "\n",
    "writer_train = SummaryWriter(trainwr_file)\n",
    "writer_test  = SummaryWriter(testwr_file)\n",
    "\n",
    "while epoch_id < num_epochs:\n",
    "    epoch_id += 1\n",
    "    \n",
    "    try:   \n",
    "        net.train()\n",
    "        train_cost, train_psnr = train_epoch()\n",
    "        \n",
    "        net.eval()\n",
    "        test_cost, test_psnr = eval_epoch()\n",
    "        \n",
    "        print(\"Epoch %d:\" % epoch_id)     \n",
    "        print(\"Epoch {0:0}, train_cost {1:.2}, psnr {2:.2}\".format(epoch_id, train_cost, train_psnr))\n",
    "        \n",
    "        writer_train.add_scalar('psnr', train_psnr, epoch_id)\n",
    "        writer_train.add_scalar('loss', train_cost, epoch_id)\n",
    "        writer_test.add_scalar('psnr', test_psnr, epoch_id)\n",
    "        writer_test.add_scalar('loss', test_cost, epoch_id)\n",
    "        \n",
    "        torch.save({'model': net, 'epoch': epoch_id}, model_file)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nKeyboardInterrupt')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
