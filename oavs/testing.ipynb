{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload, import_module\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "from PIL import Image as im\n",
    "import _pickle as pickle\n",
    "import cv2\n",
    "\n",
    "from functions import processLF, get_variable, get_numpy, psnr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    dataset_file = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\trainset\\h5\\8bit.h5\"\n",
    "    test_file    = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\testset\\h5\\8bit.h5\"\n",
    "    model_file   = r\"model\\model.pt\"\n",
    "    network_file = r\"network\"\n",
    "    img_dir      = r\"C:\\Users\\mummu\\Documents\\Datasets\\kalantari\\testset\\EXTRA\"\n",
    "    img_paper    = r\"C:\\Users\\mummu\\Documents\\Datasets\\kalantari\\testset\\PAPER\"\n",
    "    \n",
    "elif os.name == 'posix':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 1\n",
    "gamma_val      = 0.4\n",
    "lfsize         = [372, 540, 7, 7]\n",
    "batch_affine   = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToTensor()\n",
    "p = np.ndarray([1])\n",
    "q = np.ndarray([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##converting network to cuda-enabled\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "network_module = import_module(network_file)\n",
    "reload(network_module)\n",
    "\n",
    "Net = network_module.Net\n",
    "\n",
    "net = Net((lfsize[0], lfsize[1]), minibatch_size, lfsize, batchAffine=batch_affine)\n",
    "net.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_file)\n",
    "    \n",
    "    net.load_state_dict(checkpoint['model'].state_dict())    \n",
    "    print('Model successfully loaded.')\n",
    "    \n",
    "except:\n",
    "    print('No model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete\n",
    "#result = im.fromarray((get_numpy(corn[0,:3].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner1_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,3:6].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner2_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,6:9].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner3_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,9:].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner4_f.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def single_run(index, img_path = img_paper, img_name = 'Seahorse.png'):\n",
    "            \n",
    "    img = cv2.imread(os.path.join(img_path, img_name))\n",
    "                \n",
    "    img = processLF(trans(img), lfsize, gamma_val)\n",
    "\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    T = img[:, :, index[0], index[1], :].squeeze()\n",
    "    corn = img[:, :, [0, -1, 0, -1], [0, 0, -1, -1], :].squeeze()\n",
    "    \n",
    "    Y, R = synthesizeView(corn, index)\n",
    "\n",
    "    return T, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesizeView(corn, index):\n",
    "\n",
    "    p[0] = (index[0] - lfsize[2]//2)/(lfsize[2]//2)\n",
    "    q[0] = (index[1] - lfsize[3]//2)/(lfsize[3]//2)\n",
    "    \n",
    "    corn = corn.permute(2,3,0,1).reshape(12,corn.shape[0],corn.shape[1])[None,:]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y, R = net(get_variable(corn), get_variable(torch.from_numpy(p)), get_variable(torch.from_numpy(q)))\n",
    "        \n",
    "    return Y[0].permute(1,2,0), R[0].permute(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run for all examples in the folder and every perspectives\n",
    "def run_all_examples(img_path):\n",
    "        \n",
    "    files = [file for file in os.listdir(img_path) if file.endswith(\".png\")]\n",
    "    ps = np.ndarray((len(files),7,7))\n",
    "\n",
    "    for fi in range(len(files)):\n",
    "\n",
    "        file = files[fi]\n",
    "\n",
    "        print(\"Current file {}: {}\" .format(fi,file))\n",
    "\n",
    "        img = cv2.imread(os.path.join(img_path, file))\n",
    "        img = processLF(trans(img), lfsize, gamma_val)\n",
    "\n",
    "        corn = img[:, :, [0, -1, 0, -1], [0, 0, -1, -1], :].squeeze()\n",
    "\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "\n",
    "                T = get_numpy(img[:, :, i, j, :])\n",
    "                Y = get_numpy(synthesizeView(corn, [i, j]))\n",
    "\n",
    "                ps[fi,i,j] = psnr_1(T, Y)\n",
    "\n",
    "        print(\"Current PSNR: {}\" .format(ps[fi].mean()))\n",
    "    \n",
    "    return ps\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file 0: IMG_1085_eslf.png\n",
      "Current PSNR: 39.170709751534055\n",
      "Current file 1: IMG_1086_eslf.png\n",
      "Current PSNR: 37.97918624255359\n",
      "Current file 2: IMG_1184_eslf.png\n",
      "Current PSNR: 39.422777494272616\n",
      "Current file 3: IMG_1187_eslf.png\n",
      "Current PSNR: 37.81537249785996\n",
      "Current file 4: IMG_1306_eslf.png\n",
      "Current PSNR: 36.54444938521907\n",
      "Current file 5: IMG_1312_eslf.png\n",
      "Current PSNR: 39.98492219580449\n",
      "Current file 6: IMG_1316_eslf.png\n",
      "Current PSNR: 34.68500126996709\n",
      "Current file 7: IMG_1317_eslf.png\n",
      "Current PSNR: 33.826518721824876\n",
      "Current file 8: IMG_1320_eslf.png\n",
      "Current PSNR: 35.26226158491546\n",
      "Current file 9: IMG_1321_eslf.png\n",
      "Current PSNR: 39.10750948580428\n",
      "Current file 10: IMG_1324_eslf.png\n",
      "Current PSNR: 39.08973419878781\n",
      "Current file 11: IMG_1325_eslf.png\n",
      "Current PSNR: 35.481360851043746\n",
      "Current file 12: IMG_1327_eslf.png\n",
      "Current PSNR: 36.81696014968862\n",
      "Current file 13: IMG_1328_eslf.png\n",
      "Current PSNR: 38.6466767148857\n",
      "Current file 14: IMG_1340_eslf.png\n",
      "Current PSNR: 40.14082739143177\n",
      "Current file 15: IMG_1389_eslf.png\n",
      "Current PSNR: 40.206258312726554\n",
      "Current file 16: IMG_1390_eslf.png\n",
      "Current PSNR: 40.10836403650738\n",
      "Current file 17: IMG_1411_eslf.png\n",
      "Current PSNR: 33.46066466098454\n",
      "Current file 18: IMG_1419_eslf.png\n",
      "Current PSNR: 33.40510037560917\n",
      "Current file 19: IMG_1528_eslf.png\n",
      "Current PSNR: 34.93023321912983\n",
      "Current file 20: IMG_1541_eslf.png\n",
      "Current PSNR: 34.62524830836616\n",
      "Current file 21: IMG_1554_eslf.png\n",
      "Current PSNR: 31.540411895699524\n",
      "Current file 22: IMG_1555_eslf.png\n",
      "Current PSNR: 32.68469103460521\n",
      "Current file 23: IMG_1586_eslf.png\n",
      "Current PSNR: 37.16710822522315\n",
      "Current file 24: IMG_1743_eslf.png\n",
      "Current PSNR: 33.648542053609674\n"
     ]
    }
   ],
   "source": [
    "ps = run_all_examples(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=2)\n",
    "# print(ps)\n",
    "\n",
    "#for index, val in enumerate(list)\n",
    "files = [file for file in os.listdir(img_dir) if file.endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.37107159891023"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for _, fi in enumerate(files):\n",
    "ps.reshape(len(files),-1)[:,[i for i in range(49) if (i-np.array((0,6,42,48))).all()]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
