{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import pdb\n",
    "import h5py\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and processing train and test datasets\n",
    "### Using Kalantari dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test1_dir = \"Documents\\\\Datasets\\\\Kalantari\\\\TestSet\\\\PAPER\\\\\"\n",
    "#test2_dir = \"Documents\\\\Datasets\\\\Kalantari\\\\TestSet\\\\EXTRA\\\\\"\n",
    "#train1_dir = \"Documents\\\\Datasets\\\\Srinivasan\\\\\"\n",
    "#train2_dir = \"Documents\\\\Datasets\\\\Kalantari\\\\TrainingSet\\\\\"\n",
    "#os.getcwd()\n",
    "#model_dir = \"Documents\\\\Datasets\\\\Kalantari\\\\Models_300k\\\\MYTR_MAE_210K.tar\"\n",
    "#model_dir = \"Documents\\\\Datasets\\\\Kalantari\\\\Models_300k\\\\MYTR_MAE_WD1_51K.tar\"\n",
    "#model_dir = \"Documents\\\\Datasets\\\\Kalantari\\\\Models_300k\\\\OAVS-Copy5_400K.tar\"\n",
    "\n",
    "if os.name == 'posix':\n",
    "    model_dir = \"Models/OAVS_grad1_flowers.tar.waffine\"\n",
    "    #imgDir = \"../../../../Documents/Datasets/Kalantari/TestSet/PAPER/\"\n",
    "    #Network_Name = 'Networks.UDDE_000'\n",
    "    \n",
    "else:\n",
    "    model_dir = \"Models\\\\OAVS_grad1_flowers.tar.wawob\"\n",
    "    #imgDir = \"..\\\\..\\\\..\\\\..\\\\Documents\\\\Datasets\\\\Kalantari\\\\TestSet\\\\PAPER\"\n",
    "    #imgDir = \"..\\\\..\\\\..\\\\..\\\\Documents\\\\Datasets\\\\Srinivasan\\\\Flowers_8bit\\\\TestSet\"\n",
    "    imgDir = \"..\\\\..\\\\..\\\\..\\\\Documents\\\\Datasets\\\\Kalantari\\\\TestSet\\\\EXTRA\"\n",
    "    Network_Name = 'Networks.OAVS_grad1_flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_val = 0.4\n",
    "minibatch_size = 1\n",
    "lfsize = [372, 540, 7, 7] #dimensions of Lytro light fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processLF(lf):\n",
    "    \n",
    "    # Crop image\n",
    "    lf = lf[:3,:lfsize[0]*14,:lfsize[1]*14]\n",
    "    # 2D lenslet grid to 4D\n",
    "    lf = lf.view(3, lfsize[0], 14, lfsize[1], 14).permute(1, 3, 2, 4, 0)\n",
    "    # Pick the central perspectives only\n",
    "    lf = lf[:, :, (14//2)-(lfsize[2]//2):(14//2)+(lfsize[2]//2) + 1, (14//2)-(lfsize[3]//2):(14//2)+(lfsize[3]//2) + 1, :]\n",
    "    # Gamma correction\n",
    "    lf = torch.pow(lf, gamma_val)\n",
    "    # Normalize LF (-1 to 1)\n",
    "    lf = (lf * 2.0) - 1.0\n",
    "    \n",
    "    return lf\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()\n",
    "\n",
    "import math\n",
    "\n",
    "def psnr_1(img1, img2):\n",
    "    mse = np.mean( ((img1 - img2)/2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1.0\n",
    "    return 10 * math.log10(PIXEL_MAX / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()\n",
    "trans1 = transforms.ToTensor()\n",
    "p = np.ndarray([1])\n",
    "q = np.ndarray([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##converting network to cuda-enabled\n",
      "Net(\n",
      "  (f_conv0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (f_conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (f_conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (f_conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (f_conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (f_pool0): AvgPool2d(kernel_size=16, stride=16, padding=0)\n",
      "  (f_pool1): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (f_conv5): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (f_bn0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (f_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (f_bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (f_bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (f_bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (f_bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d_conv0): Conv2d(130, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "  (d_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "  (d_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
      "  (d_conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
      "  (d_conv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (d_conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (d_conv6): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (d_bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d_bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d_bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (d_bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (s_conv0): Conv2d(18, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_conv4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_conv5): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_conv6): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (s_bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (s_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (s_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (s_bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (s_bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (s_bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "sys.path.insert(1, '\\\\Networks')\n",
    "network_module = importlib.import_module(Network_Name)\n",
    "Net = network_module.Net\n",
    "\n",
    "net = Net((lfsize[0], lfsize[1]), minibatch_size, lfsize, batchAffine=True)\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "print(net)\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_dir)\n",
    "    net.load_state_dict(checkpoint['model'].state_dict())    \n",
    "    print('Model successfully loaded.')\n",
    "    \n",
    "except:\n",
    "    print('No model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete\n",
    "#result = im.fromarray((get_numpy(corn[0,:3].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner1_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,3:6].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner2_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,6:9].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner3_f.png');\n",
    "#result = im.fromarray((get_numpy(corn[0,9:].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('corner4_f.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    O_view = net(get_variable(corn), get_variable(torch.from_numpy(p)), get_variable(torch.from_numpy(q)))\n",
    "#    net_out = get_numpy(O_view)\n",
    "#    Y = get_numpy(pers)\n",
    "#\n",
    "#    ps = psnr_1(np.squeeze(net_out), np.squeeze(Y))\n",
    "#    print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file 0: Cars.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PSNR: 29.838377937562775\n",
      "Current file 1: Flower1.png\n",
      "Current PSNR: 31.267416963265916\n",
      "Current file 2: Flower2.png\n",
      "Current PSNR: 31.336501083164425\n",
      "Current file 3: IMG_1085_eslf.png\n",
      "Current PSNR: 36.95246996390464\n",
      "Current file 4: IMG_1086_eslf.png\n",
      "Current PSNR: 35.49888573774054\n",
      "Current file 5: IMG_1184_eslf.png\n",
      "Current PSNR: 35.04667170018851\n",
      "Current file 6: IMG_1187_eslf.png\n",
      "Current PSNR: 32.815261879454916\n",
      "Current file 7: IMG_1306_eslf.png\n",
      "Current PSNR: 32.77327449132135\n",
      "Current file 8: IMG_1312_eslf.png\n",
      "Current PSNR: 38.63503691703915\n",
      "Current file 9: IMG_1316_eslf.png\n",
      "Current PSNR: 21.0835681747482\n",
      "Current file 10: IMG_1317_eslf.png\n",
      "Current PSNR: 27.60736423802953\n",
      "Current file 11: IMG_1320_eslf.png\n",
      "Current PSNR: 32.38700398224729\n",
      "Current file 12: IMG_1321_eslf.png\n",
      "Current PSNR: 35.47449045535484\n",
      "Current file 13: IMG_1324_eslf.png\n",
      "Current PSNR: 38.013584655701436\n",
      "Current file 14: IMG_1325_eslf.png\n",
      "Current PSNR: 31.672742002063252\n",
      "Current file 15: IMG_1327_eslf.png\n",
      "Current PSNR: 30.308442794786245\n",
      "Current file 16: IMG_1328_eslf.png\n",
      "Current PSNR: 31.75929799188751\n",
      "Current file 17: IMG_1340_eslf.png\n",
      "Current PSNR: 24.967456952844916\n",
      "Current file 18: IMG_1389_eslf.png\n",
      "Current PSNR: 31.694110117276143\n",
      "Current file 19: IMG_1390_eslf.png\n",
      "Current PSNR: 37.667353642950204\n",
      "Current file 20: IMG_1411_eslf.png\n",
      "Current PSNR: 29.793900733204733\n",
      "Current file 21: IMG_1419_eslf.png\n",
      "Current PSNR: 32.53809159570112\n",
      "Current file 22: IMG_1528_eslf.png\n",
      "Current PSNR: 22.746781277923482\n",
      "Current file 23: IMG_1541_eslf.png\n",
      "Current PSNR: 27.895156172436355\n",
      "Current file 24: IMG_1554_eslf.png\n",
      "Current PSNR: 26.93560861238445\n",
      "Current file 25: IMG_1555_eslf.png\n",
      "Current PSNR: 30.349959973380507\n",
      "Current file 26: IMG_1586_eslf.png\n",
      "Current PSNR: 34.674694382457695\n",
      "Current file 27: IMG_1743_eslf.png\n",
      "Current PSNR: 28.87883167855268\n",
      "Current file 28: Rock.png\n",
      "Current PSNR: 28.488023545702028\n",
      "Current file 29: Seahorse.png\n",
      "Current PSNR: 33.66818487846317\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "files = [file for file in os.listdir(imgDir) if file.endswith(\".png\")]\n",
    "\n",
    "ps = np.ndarray((len(files),7,7))\n",
    "\n",
    "for fi in range(len(files)):\n",
    "\n",
    "    file = files[fi]\n",
    "    \n",
    "    print(\"Current file {}: {}\" .format(fi,file))\n",
    "    \n",
    "    img = cv2.imread(os.path.join(imgDir, file))\n",
    "                \n",
    "    img = processLF(trans1(img))\n",
    "\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            pers = img[:, :, i, j, :].squeeze()\n",
    "            corn = img[:, :, [0, -1, 0, -1], [0, 0, -1, -1], :].squeeze()\n",
    "\n",
    "            p[0] = (i - lfsize[2]//2)/(lfsize[2]//2)\n",
    "            q[0] = (j - lfsize[3]//2)/(lfsize[3]//2)\n",
    "\n",
    "            corn = corn.permute(2,3,0,1).reshape(12,pers.shape[0],pers.shape[1])[None,:]\n",
    "            pers = pers[None,:].permute(0,3,1,2)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                O_view = net(get_variable(corn), get_variable(torch.from_numpy(p)), get_variable(torch.from_numpy(q)))\n",
    "\n",
    "                net_out = get_numpy(O_view)\n",
    "                Y = get_numpy(pers)\n",
    "\n",
    "                ps[fi,i,j] = psnr_1(np.squeeze(net_out), np.squeeze(Y))      \n",
    "\n",
    "                del O_view            \n",
    "                torch.cuda.empty_cache()\n",
    "    print(\"Current PSNR: {}\" .format(ps[fi].mean()))\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[29.82 30.31 30.47 30.53 30.62 30.56 30.01]\n",
      "  [30.77 31.34 31.42 31.48 31.68 31.77 31.12]\n",
      "  [31.15 31.77 31.98 32.09 32.33 32.22 31.53]\n",
      "  [30.86 31.44 32.02 32.26 32.34 32.21 31.54]\n",
      "  [30.78 31.81 32.23 32.41 32.41 32.34 31.55]\n",
      "  [30.75 31.63 31.97 31.89 31.84 31.74 30.91]\n",
      "  [30.04 30.91 31.31 31.26 31.2  30.76 29.88]]\n",
      "\n",
      " [[31.43 32.03 31.99 31.94 31.93 31.72 31.35]\n",
      "  [31.83 32.4  32.3  32.14 32.15 31.96 31.57]\n",
      "  [32.16 32.53 32.43 32.28 32.29 32.12 31.65]\n",
      "  [32.1  32.4  32.38 32.26 32.34 32.07 31.65]\n",
      "  [31.96 32.25 32.19 32.16 32.22 32.05 31.69]\n",
      "  [31.46 31.9  31.9  31.86 31.91 31.68 31.22]\n",
      "  [30.81 31.27 31.41 31.42 31.49 31.04 30.52]]\n",
      "\n",
      " [[30.56 30.91 30.99 30.8  30.69 30.41 29.44]\n",
      "  [31.28 31.95 32.05 31.92 31.85 31.29 30.17]\n",
      "  [31.72 32.26 32.41 32.25 32.24 31.68 30.31]\n",
      "  [31.22 31.95 32.16 32.06 32.09 31.51 30.31]\n",
      "  [30.92 31.57 31.76 31.72 31.7  31.26 30.2 ]\n",
      "  [29.85 30.52 30.7  30.75 30.79 30.18 29.29]\n",
      "  [29.02 29.58 29.91 29.91 29.94 29.15 28.28]]\n",
      "\n",
      " [[27.6  27.96 27.65 27.37 27.11 27.03 26.76]\n",
      "  [28.17 28.64 28.33 28.09 27.87 27.82 27.47]\n",
      "  [27.86 28.33 28.21 28.08 27.97 27.86 27.54]\n",
      "  [27.57 28.07 27.96 27.97 27.83 27.74 27.44]\n",
      "  [27.98 28.6  28.53 28.43 28.45 28.39 28.13]\n",
      "  [28.24 28.89 28.77 28.69 28.6  28.63 28.39]\n",
      "  [27.29 27.84 27.84 27.69 27.44 27.37 27.13]]\n",
      "\n",
      " [[31.96 33.19 33.33 33.32 33.64 33.7  33.32]\n",
      "  [32.3  33.29 33.62 33.91 34.16 34.26 33.55]\n",
      "  [32.32 33.48 33.85 34.23 34.44 34.4  33.71]\n",
      "  [32.73 33.69 34.15 34.41 34.65 34.49 33.85]\n",
      "  [32.96 33.96 34.32 34.46 34.51 34.53 33.76]\n",
      "  [33.15 33.95 34.07 34.13 34.01 33.67 32.76]\n",
      "  [32.62 33.25 33.31 33.27 33.18 32.43 31.71]]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(ps)\n",
    "\n",
    "#for index, val in enumerate(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.902742582728166"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for _, fi in enumerate(files):\n",
    "ps.reshape(len(files),-1)[:,[i for i in range(49) if (i-np.array((0,6,42,48))).all()]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = im.open(imgDir + 'Cars.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.291147203083646"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.reshape(-1,len(files))[[i for i in range(49) if (i-np.array((0,6,42,48))).all()]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.62863017513677"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.reshape(-1,len(files)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 49)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.reshape(len(files),-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file 4: Seahorse.png\n",
      "> c:\\users\\mummu\\documents\\github\\deep-learning-projects\\oavs-navarro\\networks\\oavs_grad1_flowers.py(219)forward()\n",
      "-> return I\n",
      "(Pdb) result = im.fromarray((get_numpy(d[0,0]+4)/8 * 255).astype(np.uint8));result.save('depth1.png');\n",
      "*** NameError: name 'im' is not defined\n",
      "(Pdb) from PIL import Image as im\n",
      "(Pdb) result = im.fromarray((get_numpy(d[0,0]+4)/8 * 255).astype(np.uint8));result.save('depth1.png');\n",
      "(Pdb) result = im.fromarray((get_numpy(x_00[0].permute(1,2,0)+1)/2 * 255).astype(np.uint8));result.save('image1.png');\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1d00b810cae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mO_view\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mnet_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mO_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Deep-Learning-Projects\\OAVS-navarro\\Networks\\OAVS_grad1_flowers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, p, q)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Deep-Learning-Projects\\OAVS-navarro\\Networks\\OAVS_grad1_flowers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, p, q)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "files = [file for file in os.listdir(imgDir) if file.endswith(\".png\")]\n",
    "\n",
    "ps = np.ndarray((len(files),7,7))\n",
    "\n",
    "fi = files.index(\"Seahorse.png\")\n",
    "\n",
    "file = files[fi]\n",
    "\n",
    "print(\"Current file {}: {}\" .format(fi,file))\n",
    "\n",
    "img = cv2.imread(os.path.join(imgDir, file))\n",
    "\n",
    "img = processLF(trans1(img))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "pers = img[:, :, i, j, :].squeeze()\n",
    "corn = img[:, :, [0, -1, 0, -1], [0, 0, -1, -1], :].squeeze()\n",
    "\n",
    "#pdb.set_trace()\n",
    "\n",
    "p[0] = (i - lfsize[2]//2)/(lfsize[2]//2)\n",
    "q[0] = (j - lfsize[3]//2)/(lfsize[3]//2)\n",
    "\n",
    "corn = corn.permute(2,3,0,1).reshape(12,pers.shape[0],pers.shape[1])[None,:]\n",
    "pers = pers[None,:].permute(0,3,1,2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    O_view = net(get_variable(corn), get_variable(torch.from_numpy(p)), get_variable(torch.from_numpy(q)))\n",
    "\n",
    "    net_out = get_numpy(O_view)\n",
    "    Y = get_numpy(pers)\n",
    "\n",
    "    ps[fi,i,j] = psnr_1(np.squeeze(net_out), np.squeeze(Y))      \n",
    "\n",
    "    del O_view            \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
