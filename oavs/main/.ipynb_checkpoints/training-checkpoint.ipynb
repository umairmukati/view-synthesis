{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload, import_module\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "from PIL import Image as im\n",
    "import _pickle as pickle\n",
    "\n",
    "\n",
    "from functions import MyDataset, customTransform, get_variable, get_numpy, compute_gradient, psnr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    dataset_file = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\trainset\\h5\\8bit.h5\"\n",
    "    test_file    = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\testset\\h5\\8bit.h5\"\n",
    "    model_file   = r\"model\\model.pt\"\n",
    "    network_file = r\"network_revised\"\n",
    "    trainwr_file = r\"runs\\train\"\n",
    "    testwr_file  = r\"runs\\test\"\n",
    "elif os.name == 'posix':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size     = 192\n",
    "batch_size     = 300\n",
    "minibatch_size = 8\n",
    "gamma_val      = 0.4\n",
    "lfsize         = [372, 540, 7, 7]\n",
    "num_workers    = 0\n",
    "num_test       = 10\n",
    "num_minibatch  = batch_size//minibatch_size\n",
    "batch_affine   = True\n",
    "num_epochs     = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INITIALIZE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                     transforms.Lambda(customTransform)])\n",
    "\n",
    "train_dataset  = MyDataset(dataset_file, lfsize, data_transform)\n",
    "test_dataset   = MyDataset(test_file, lfsize, data_transform)\n",
    "\n",
    "train_loader   = torch.utils.data.DataLoader(train_dataset, batch_size=minibatch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader    = torch.utils.data.DataLoader(train_dataset, batch_size=minibatch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOKING FOR SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##converting network to cuda-enabled\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "network_module = import_module(network_file)\n",
    "reload(network_module)\n",
    "Net = network_module.Net\n",
    "\n",
    "net = Net((patch_size, patch_size), minibatch_size, lfsize, batchAffine=batch_affine)\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_file)\n",
    "    \n",
    "    epoch_id = checkpoint['epoch']\n",
    "    net.load_state_dict(checkpoint['model'].state_dict())\n",
    "    print('Model successfully loaded.')\n",
    "    \n",
    "except:\n",
    "    print('No model.')\n",
    "    epoch_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def count_parameters(model): return list(name for name, param in model.named_parameters() if param.requires_grad == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256649"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = nn.L1Loss()\n",
    "criterion2 = nn.L1Loss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    costs = []\n",
    "    psnr_vec = []\n",
    "            \n",
    "    for batch_num in range(num_minibatch):\n",
    "        \n",
    "        # fetching training batch\n",
    "        corners, pers, ind = next(iter(train_loader))\n",
    "        \n",
    "        # converting to trainable variables\n",
    "        X_corners = get_variable(corners)\n",
    "        T_view = get_variable(pers)\n",
    "        p = get_variable(ind[:,0])\n",
    "        q = get_variable(ind[:,-1])\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        O_view, _, _ = net(X_corners, p, q)\n",
    "        \n",
    "        # Computing batch loss\n",
    "        batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view),\n",
    "                                                          compute_gradient(T_view))\n",
    "        \n",
    "        # Backpropagation\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # recording performance\n",
    "        costs.append(get_numpy(batch_loss))\n",
    "        net_out = get_numpy(O_view)\n",
    "        Y = get_numpy(T_view)      \n",
    "        psnr_vec.append([psnr_1(np.squeeze(net_out[i]), np.squeeze(Y[i])) for i in range(minibatch_size)])\n",
    "    \n",
    "        \n",
    "    return np.mean(costs), np.mean(psnr_vec)\n",
    "\n",
    "def eval_epoch():\n",
    "    costs = []\n",
    "    psnr_vec = []\n",
    "    \n",
    "    for batch_num in range(num_test):\n",
    "        \n",
    "        # fetching training batch\n",
    "        corners, pers, ind = next(iter(test_loader))\n",
    "        \n",
    "        # converting to trainable variables\n",
    "        X_corners = get_variable(corners)\n",
    "        T_view = get_variable(pers)\n",
    "        p = get_variable(ind[:,0])\n",
    "        q = get_variable(ind[:,-1])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            O_view, _, _ = net(X_corners, p, q)\n",
    "            \n",
    "            # Computing batch loss\n",
    "            batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view), compute_gradient(T_view))\n",
    "            \n",
    "            # recording performance\n",
    "            costs.append(get_numpy(batch_loss))\n",
    "            net_out = get_numpy(O_view)\n",
    "            Y = get_numpy(T_view)\n",
    "            psnr_vec.append([psnr_1(np.squeeze(net_out[i]), np.squeeze(Y[i])) for i in range(minibatch_size)])\n",
    "\n",
    "    return np.mean(costs), np.mean(psnr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302:\n",
      "Epoch 302, train_cost 0.039, psnr 4e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GroupNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303:\n",
      "Epoch 303, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 304:\n",
      "Epoch 304, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 305:\n",
      "Epoch 305, train_cost 0.041, psnr 4e+01\n",
      "Epoch 306:\n",
      "Epoch 306, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 307:\n",
      "Epoch 307, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 308:\n",
      "Epoch 308, train_cost 0.041, psnr 4e+01\n",
      "Epoch 309:\n",
      "Epoch 309, train_cost 0.039, psnr 4e+01\n",
      "Epoch 310:\n",
      "Epoch 310, train_cost 0.04, psnr 4e+01\n",
      "Epoch 311:\n",
      "Epoch 311, train_cost 0.044, psnr 4e+01\n",
      "Epoch 312:\n",
      "Epoch 312, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 313:\n",
      "Epoch 313, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 314:\n",
      "Epoch 314, train_cost 0.041, psnr 4e+01\n",
      "Epoch 315:\n",
      "Epoch 315, train_cost 0.041, psnr 4e+01\n",
      "Epoch 316:\n",
      "Epoch 316, train_cost 0.036, psnr 4.1e+01\n",
      "Epoch 317:\n",
      "Epoch 317, train_cost 0.04, psnr 4e+01\n",
      "Epoch 318:\n",
      "Epoch 318, train_cost 0.04, psnr 4e+01\n",
      "Epoch 319:\n",
      "Epoch 319, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 320:\n",
      "Epoch 320, train_cost 0.04, psnr 4e+01\n",
      "Epoch 321:\n",
      "Epoch 321, train_cost 0.039, psnr 4e+01\n",
      "Epoch 322:\n",
      "Epoch 322, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 323:\n",
      "Epoch 323, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 324:\n",
      "Epoch 324, train_cost 0.04, psnr 4e+01\n",
      "Epoch 325:\n",
      "Epoch 325, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 326:\n",
      "Epoch 326, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 327:\n",
      "Epoch 327, train_cost 0.04, psnr 4e+01\n",
      "Epoch 328:\n",
      "Epoch 328, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 329:\n",
      "Epoch 329, train_cost 0.041, psnr 4e+01\n",
      "Epoch 330:\n",
      "Epoch 330, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 331:\n",
      "Epoch 331, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 332:\n",
      "Epoch 332, train_cost 0.039, psnr 4e+01\n",
      "Epoch 333:\n",
      "Epoch 333, train_cost 0.036, psnr 4.1e+01\n",
      "Epoch 334:\n",
      "Epoch 334, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 335:\n",
      "Epoch 335, train_cost 0.04, psnr 4e+01\n",
      "Epoch 336:\n",
      "Epoch 336, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 337:\n",
      "Epoch 337, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 338:\n",
      "Epoch 338, train_cost 0.041, psnr 4e+01\n",
      "Epoch 339:\n",
      "Epoch 339, train_cost 0.041, psnr 4e+01\n",
      "Epoch 340:\n",
      "Epoch 340, train_cost 0.039, psnr 4e+01\n",
      "Epoch 341:\n",
      "Epoch 341, train_cost 0.04, psnr 4e+01\n",
      "Epoch 342:\n",
      "Epoch 342, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 343:\n",
      "Epoch 343, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 344:\n",
      "Epoch 344, train_cost 0.039, psnr 4e+01\n",
      "Epoch 345:\n",
      "Epoch 345, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 346:\n",
      "Epoch 346, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 347:\n",
      "Epoch 347, train_cost 0.041, psnr 4e+01\n",
      "Epoch 348:\n",
      "Epoch 348, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 349:\n",
      "Epoch 349, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 350:\n",
      "Epoch 350, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 351:\n",
      "Epoch 351, train_cost 0.04, psnr 4e+01\n",
      "Epoch 352:\n",
      "Epoch 352, train_cost 0.039, psnr 4e+01\n",
      "Epoch 353:\n",
      "Epoch 353, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 354:\n",
      "Epoch 354, train_cost 0.042, psnr 4e+01\n",
      "Epoch 355:\n",
      "Epoch 355, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 356:\n",
      "Epoch 356, train_cost 0.039, psnr 4e+01\n",
      "Epoch 357:\n",
      "Epoch 357, train_cost 0.04, psnr 4e+01\n",
      "Epoch 358:\n",
      "Epoch 358, train_cost 0.04, psnr 4e+01\n",
      "Epoch 359:\n",
      "Epoch 359, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 360:\n",
      "Epoch 360, train_cost 0.039, psnr 4e+01\n",
      "Epoch 361:\n",
      "Epoch 361, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 362:\n",
      "Epoch 362, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 363:\n",
      "Epoch 363, train_cost 0.04, psnr 4e+01\n",
      "Epoch 364:\n",
      "Epoch 364, train_cost 0.039, psnr 4e+01\n",
      "Epoch 365:\n",
      "Epoch 365, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 366:\n",
      "Epoch 366, train_cost 0.04, psnr 4e+01\n",
      "Epoch 367:\n",
      "Epoch 367, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 368:\n",
      "Epoch 368, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 369:\n",
      "Epoch 369, train_cost 0.039, psnr 4e+01\n",
      "Epoch 370:\n",
      "Epoch 370, train_cost 0.041, psnr 4e+01\n",
      "Epoch 371:\n",
      "Epoch 371, train_cost 0.039, psnr 4e+01\n",
      "Epoch 372:\n",
      "Epoch 372, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 373:\n",
      "Epoch 373, train_cost 0.04, psnr 4e+01\n",
      "Epoch 374:\n",
      "Epoch 374, train_cost 0.041, psnr 4e+01\n",
      "Epoch 375:\n",
      "Epoch 375, train_cost 0.04, psnr 4e+01\n",
      "Epoch 376:\n",
      "Epoch 376, train_cost 0.041, psnr 4e+01\n",
      "Epoch 377:\n",
      "Epoch 377, train_cost 0.036, psnr 4.1e+01\n",
      "Epoch 378:\n",
      "Epoch 378, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 379:\n",
      "Epoch 379, train_cost 0.041, psnr 4e+01\n",
      "Epoch 380:\n",
      "Epoch 380, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 381:\n",
      "Epoch 381, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 382:\n",
      "Epoch 382, train_cost 0.04, psnr 4e+01\n",
      "Epoch 383:\n",
      "Epoch 383, train_cost 0.036, psnr 4.1e+01\n",
      "Epoch 384:\n",
      "Epoch 384, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 385:\n",
      "Epoch 385, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 386:\n",
      "Epoch 386, train_cost 0.04, psnr 4e+01\n",
      "Epoch 387:\n",
      "Epoch 387, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 388:\n",
      "Epoch 388, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 389:\n",
      "Epoch 389, train_cost 0.041, psnr 4e+01\n",
      "Epoch 390:\n",
      "Epoch 390, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 391:\n",
      "Epoch 391, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 392:\n",
      "Epoch 392, train_cost 0.041, psnr 4e+01\n",
      "Epoch 393:\n",
      "Epoch 393, train_cost 0.041, psnr 4e+01\n",
      "Epoch 394:\n",
      "Epoch 394, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 395:\n",
      "Epoch 395, train_cost 0.041, psnr 4e+01\n",
      "Epoch 396:\n",
      "Epoch 396, train_cost 0.039, psnr 4e+01\n",
      "Epoch 397:\n",
      "Epoch 397, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 398:\n",
      "Epoch 398, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 399:\n",
      "Epoch 399, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 400:\n",
      "Epoch 400, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 401:\n",
      "Epoch 401, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 402:\n",
      "Epoch 402, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 403:\n",
      "Epoch 403, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 404:\n",
      "Epoch 404, train_cost 0.038, psnr 4e+01\n",
      "Epoch 405:\n",
      "Epoch 405, train_cost 0.039, psnr 4e+01\n",
      "Epoch 406:\n",
      "Epoch 406, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 407:\n",
      "Epoch 407, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 408:\n",
      "Epoch 408, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 409:\n",
      "Epoch 409, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 410:\n",
      "Epoch 410, train_cost 0.04, psnr 4e+01\n",
      "Epoch 411:\n",
      "Epoch 411, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 412:\n",
      "Epoch 412, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 413:\n",
      "Epoch 413, train_cost 0.04, psnr 4e+01\n",
      "Epoch 414:\n",
      "Epoch 414, train_cost 0.039, psnr 4e+01\n",
      "Epoch 415:\n",
      "Epoch 415, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 416:\n",
      "Epoch 416, train_cost 0.042, psnr 4e+01\n",
      "Epoch 417:\n",
      "Epoch 417, train_cost 0.039, psnr 4e+01\n",
      "Epoch 418:\n",
      "Epoch 418, train_cost 0.04, psnr 4e+01\n",
      "Epoch 419:\n",
      "Epoch 419, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 420:\n",
      "Epoch 420, train_cost 0.04, psnr 4e+01\n",
      "Epoch 421:\n",
      "Epoch 421, train_cost 0.041, psnr 4e+01\n",
      "Epoch 422:\n",
      "Epoch 422, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 423:\n",
      "Epoch 423, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 424:\n",
      "Epoch 424, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 425:\n",
      "Epoch 425, train_cost 0.04, psnr 4e+01\n",
      "Epoch 426:\n",
      "Epoch 426, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 427:\n",
      "Epoch 427, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 428:\n",
      "Epoch 428, train_cost 0.04, psnr 4e+01\n",
      "Epoch 429:\n",
      "Epoch 429, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 430:\n",
      "Epoch 430, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 431:\n",
      "Epoch 431, train_cost 0.039, psnr 4e+01\n",
      "Epoch 432:\n",
      "Epoch 432, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 433:\n",
      "Epoch 433, train_cost 0.04, psnr 4e+01\n",
      "Epoch 434:\n",
      "Epoch 434, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 435:\n",
      "Epoch 435, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 436:\n",
      "Epoch 436, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 437:\n",
      "Epoch 437, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 438:\n",
      "Epoch 438, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 439:\n",
      "Epoch 439, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 440:\n",
      "Epoch 440, train_cost 0.04, psnr 4e+01\n",
      "Epoch 441:\n",
      "Epoch 441, train_cost 0.039, psnr 4e+01\n",
      "Epoch 442:\n",
      "Epoch 442, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 443:\n",
      "Epoch 443, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 444:\n",
      "Epoch 444, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 445:\n",
      "Epoch 445, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 446:\n",
      "Epoch 446, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 447:\n",
      "Epoch 447, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 448:\n",
      "Epoch 448, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 449:\n",
      "Epoch 449, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 450:\n",
      "Epoch 450, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 451:\n",
      "Epoch 451, train_cost 0.039, psnr 4e+01\n",
      "Epoch 452:\n",
      "Epoch 452, train_cost 0.039, psnr 4e+01\n",
      "Epoch 453:\n",
      "Epoch 453, train_cost 0.042, psnr 4e+01\n",
      "Epoch 454:\n",
      "Epoch 454, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 455:\n",
      "Epoch 455, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 456:\n",
      "Epoch 456, train_cost 0.042, psnr 4e+01\n",
      "Epoch 457:\n",
      "Epoch 457, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 458:\n",
      "Epoch 458, train_cost 0.04, psnr 4e+01\n",
      "Epoch 459:\n",
      "Epoch 459, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 460:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460, train_cost 0.039, psnr 4e+01\n",
      "Epoch 461:\n",
      "Epoch 461, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 462:\n",
      "Epoch 462, train_cost 0.041, psnr 4e+01\n",
      "Epoch 463:\n",
      "Epoch 463, train_cost 0.041, psnr 4e+01\n",
      "Epoch 464:\n",
      "Epoch 464, train_cost 0.036, psnr 4.1e+01\n",
      "Epoch 465:\n",
      "Epoch 465, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 466:\n",
      "Epoch 466, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 467:\n",
      "Epoch 467, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 468:\n",
      "Epoch 468, train_cost 0.039, psnr 4.1e+01\n",
      "Epoch 469:\n",
      "Epoch 469, train_cost 0.04, psnr 4.1e+01\n",
      "Epoch 470:\n",
      "Epoch 470, train_cost 0.041, psnr 4e+01\n",
      "Epoch 471:\n",
      "Epoch 471, train_cost 0.038, psnr 4.1e+01\n",
      "Epoch 472:\n",
      "Epoch 472, train_cost 0.041, psnr 4e+01\n",
      "Epoch 473:\n",
      "Epoch 473, train_cost 0.037, psnr 4.1e+01\n",
      "Epoch 474:\n",
      "Epoch 474, train_cost 0.04, psnr 4e+01\n",
      "Epoch 475:\n",
      "Epoch 475, train_cost 0.041, psnr 4e+01\n",
      "Epoch 476:\n",
      "Epoch 476, train_cost 0.041, psnr 4e+01\n",
      "Epoch 477:\n",
      "Epoch 477, train_cost 0.038, psnr 4.1e+01\n"
     ]
    }
   ],
   "source": [
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "\n",
    "writer_train = SummaryWriter(trainwr_file)\n",
    "writer_test  = SummaryWriter(testwr_file)\n",
    "\n",
    "while epoch_id < num_epochs:\n",
    "    epoch_id += 1\n",
    "    \n",
    "    try:   \n",
    "        net.train()\n",
    "        train_cost, train_psnr = train_epoch()\n",
    "        \n",
    "        net.eval()\n",
    "        test_cost, test_psnr = eval_epoch()\n",
    "        \n",
    "        print(\"Epoch %d:\" % epoch_id)     \n",
    "        print(\"Epoch {0:0}, train_cost {1:.2}, psnr {2:.2}\".format(epoch_id, train_cost, train_psnr))\n",
    "        \n",
    "        writer_train.add_scalar('psnr', train_psnr, epoch_id)\n",
    "        writer_train.add_scalar('loss', train_cost, epoch_id)\n",
    "        writer_test.add_scalar('psnr', test_psnr, epoch_id)\n",
    "        writer_test.add_scalar('loss', test_cost, epoch_id)\n",
    "        \n",
    "        torch.save({'model': net, 'epoch': epoch_id}, model_file)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nKeyboardInterrupt')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
