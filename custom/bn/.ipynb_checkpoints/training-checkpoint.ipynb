{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload, import_module\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "from PIL import Image as im\n",
    "import _pickle as pickle\n",
    "\n",
    "\n",
    "from functions import MyDataset, customTransform, get_variable, get_numpy, compute_gradient, psnr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    dataset_file = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\trainset\\h5\\8bit.h5\"\n",
    "    test_file    = r\"C:\\Users\\mummu\\Documents\\Datasets\\srinivasan\\testset\\h5\\8bit.h5\"\n",
    "    model_file   = r\"model\\model.pt\"\n",
    "    network_file = r\"network\"\n",
    "    trainwr_file = r\"runs\\train\"\n",
    "    testwr_file  = r\"runs\\test\"\n",
    "elif os.name == 'posix':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size     = 192\n",
    "batch_size     = 300\n",
    "minibatch_size = 3\n",
    "gamma_val      = 0.4\n",
    "lfsize         = [372, 540, 7, 7]\n",
    "num_workers    = 0\n",
    "num_test       = 10\n",
    "num_minibatch  = batch_size//minibatch_size\n",
    "batch_affine   = True\n",
    "num_epochs     = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INITIALIZE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                     transforms.Lambda(customTransform)])\n",
    "\n",
    "train_dataset  = MyDataset(dataset_file, lfsize, data_transform)\n",
    "test_dataset   = MyDataset(test_file, lfsize, data_transform)\n",
    "\n",
    "train_loader   = torch.utils.data.DataLoader(train_dataset, batch_size=minibatch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader    = torch.utils.data.DataLoader(train_dataset, batch_size=minibatch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOOKING FOR SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##converting network to cuda-enabled\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "network_module = import_module(network_file)\n",
    "reload(network_module)\n",
    "Net = network_module.Net\n",
    "\n",
    "net = Net((patch_size, patch_size), minibatch_size, lfsize, batchAffine=batch_affine)\n",
    "if torch.cuda.is_available():\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_file)\n",
    "    \n",
    "    epoch_id = checkpoint['epoch']\n",
    "    net.load_state_dict(checkpoint['model'].state_dict())\n",
    "    print('Model successfully loaded.')\n",
    "    \n",
    "except:\n",
    "    print('No model.')\n",
    "    epoch_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = nn.L1Loss()\n",
    "criterion2 = nn.L1Loss()\n",
    "criterion3 = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    costs = []\n",
    "    psnr_vec = []\n",
    "            \n",
    "    for batch_num in range(num_minibatch):\n",
    "        \n",
    "        # fetching training batch\n",
    "        corners, pers, ind = next(iter(train_loader))\n",
    "        \n",
    "        # converting to trainable variables\n",
    "        X_corners = get_variable(corners)\n",
    "        T_view = get_variable(pers)\n",
    "        p = get_variable(ind[:,0])\n",
    "        q = get_variable(ind[:,-1])\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        O_view, M = net(X_corners, p, q)\n",
    "        \n",
    "        # Computing batch loss\n",
    "        batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view), compute_gradient(T_view)) \\\n",
    "                    + 0.5*((M.reshape(-1,12).mean(0))**2).sum()\n",
    "        \n",
    "        # Backpropagation\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # recording performance\n",
    "        costs.append(get_numpy(batch_loss))\n",
    "        net_out = get_numpy(O_view)\n",
    "        Y = get_numpy(T_view)      \n",
    "        psnr_vec.append([psnr_1(np.squeeze(net_out[i]), np.squeeze(Y[i])) for i in range(minibatch_size)])\n",
    "    \n",
    "        \n",
    "    return np.mean(costs), np.mean(psnr_vec)\n",
    "\n",
    "def eval_epoch():\n",
    "    costs = []\n",
    "    psnr_vec = []\n",
    "    \n",
    "    for batch_num in range(num_test):\n",
    "        \n",
    "        # fetching training batch\n",
    "        corners, pers, ind = next(iter(test_loader))\n",
    "        \n",
    "        # converting to trainable variables\n",
    "        X_corners = get_variable(corners)\n",
    "        T_view = get_variable(pers)\n",
    "        p = get_variable(ind[:,0])\n",
    "        q = get_variable(ind[:,-1])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            O_view = net(X_corners, p, q)\n",
    "            \n",
    "            # Computing batch loss\n",
    "            batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view), compute_gradient(T_view))\n",
    "            \n",
    "            # recording performance\n",
    "            costs.append(get_numpy(batch_loss))\n",
    "            net_out = get_numpy(O_view)\n",
    "            Y = get_numpy(T_view)\n",
    "            psnr_vec.append([psnr_1(np.squeeze(net_out[i]), np.squeeze(Y[i])) for i in range(minibatch_size)])\n",
    "\n",
    "    return np.mean(costs), np.mean(psnr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(245)forward()\n",
      "-> self.D[:,0,:,:,1] = p[:,None,None]*(self.lfsize[2] // 2) + self.lfsize[2] // 2\n",
      "(Pdb) n\n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(246)forward()\n",
      "-> self.D[:,0,:,:,0] = q[:,None,None]*(self.lfsize[3] // 2) + self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(249)forward()\n",
      "-> self.D[:,1,:,:,1] = p[:,None,None]*(self.lfsize[2] // 2) + self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(250)forward()\n",
      "-> self.D[:,1,:,:,0] = q[:,None,None]*(self.lfsize[3] // 2) - self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(253)forward()\n",
      "-> self.D[:,2,:,:,1] = p[:,None,None]*(self.lfsize[2] // 2) - self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(254)forward()\n",
      "-> self.D[:,2,:,:,0] = q[:,None,None]*(self.lfsize[3] // 2) + self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(257)forward()\n",
      "-> self.D[:,3,:,:,1] = p[:,None,None]*(self.lfsize[2] // 2) - self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(258)forward()\n",
      "-> self.D[:,3,:,:,0] = q[:,None,None]*(self.lfsize[3] // 2) - self.lfsize[2] // 2\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(260)forward()\n",
      "-> self.P[:,:,:,:] = p[:,None,None,None]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(261)forward()\n",
      "-> self.Q[:,:,:,:] = q[:,None,None,None]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(264)forward()\n",
      "-> x_00 = x[:,:3]       # 0:3 top-left\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(265)forward()\n",
      "-> x_01 = x[:,6:9]      # 6:9 top-right\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(266)forward()\n",
      "-> x_10 = x[:,3:6]      # 3:6 bottom-left\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(267)forward()\n",
      "-> x_11 = x[:,9:]       # 9:12 bottom-right\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(270)forward()\n",
      "-> FH_00 = self.fh_cnn(x_00); FHT_00 = self.fh_cnn(x_00.permute(0,1,3,2))\n",
      "(Pdb) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mummu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(271)forward()\n",
      "-> FH_01 = self.fh_cnn(x_01); FHT_01 = self.fh_cnn(x_01.permute(0,1,3,2))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(272)forward()\n",
      "-> FH_10 = self.fh_cnn(x_10); FHT_10 = self.fh_cnn(x_10.permute(0,1,3,2))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(273)forward()\n",
      "-> FH_11 = self.fh_cnn(x_11); FHT_11 = self.fh_cnn(x_11.permute(0,1,3,2))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(275)forward()\n",
      "-> FD_00 = self.fd_cnn(x_00)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(276)forward()\n",
      "-> FDT_01 = self.fd_cnn(x_01.flip(2))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(277)forward()\n",
      "-> FDT_10 = self.fd_cnn(x_10.flip(2))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(278)forward()\n",
      "-> FD_11 = self.fd_cnn(x_11)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(281)forward()\n",
      "-> d_TH = self.dh_cnn(torch.cat((FH_00, FH_01), 1))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(282)forward()\n",
      "-> d_BH = self.dh_cnn(torch.cat((FH_10, FH_11), 1))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(283)forward()\n",
      "-> d_LV = self.dh_cnn(torch.cat((FHT_00, FHT_10), 1)).permute(0,1,3,2)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(284)forward()\n",
      "-> d_RV = self.dh_cnn(torch.cat((FHT_01, FHT_11), 1)).permute(0,1,3,2)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(286)forward()\n",
      "-> d_BD = self.dd_cnn(torch.cat((FD_00, FD_11), 1))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(287)forward()\n",
      "-> d_FD = self.dd_cnn(torch.cat((FDT_10, FDT_01), 1)).flip(2)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(289)forward()\n",
      "-> Dh_00 = d_TH[:,0,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,0]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(290)forward()\n",
      "-> Dh_01 = d_TH[:,1,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,1]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(291)forward()\n",
      "-> Dh_10 = d_BH[:,0,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,2]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(292)forward()\n",
      "-> Dh_11 = d_BH[:,1,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,3]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(294)forward()\n",
      "-> Dv_00 = d_LV[:,0,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,0]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(295)forward()\n",
      "-> Dv_01 = d_RV[:,0,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,1]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(296)forward()\n",
      "-> Dv_10 = d_LV[:,1,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,2]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(297)forward()\n",
      "-> Dv_11 = d_RV[:,1,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,3]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(299)forward()\n",
      "-> Dd_00 = d_BD[:,0,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,0]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(300)forward()\n",
      "-> Dd_01 = d_FD[:,1,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,1]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(301)forward()\n",
      "-> Dd_10 = d_FD[:,0,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,2]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(302)forward()\n",
      "-> Dd_11 = d_BD[:,1,:,:].unsqueeze(3).repeat(1,1,1,2)*self.D[:,3]\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(306)forward()\n",
      "-> Wh_00 = F.grid_sample(x_00, self.grid + Dh_00/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(307)forward()\n",
      "-> Wh_01 = F.grid_sample(x_01, self.grid + Dh_01/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(308)forward()\n",
      "-> Wh_10 = F.grid_sample(x_10, self.grid + Dh_10/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(309)forward()\n",
      "-> Wh_11 = F.grid_sample(x_11, self.grid + Dh_11/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(311)forward()\n",
      "-> Wv_00 = F.grid_sample(x_00, self.grid + Dv_00/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(312)forward()\n",
      "-> Wv_01 = F.grid_sample(x_01, self.grid + Dv_01/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(313)forward()\n",
      "-> Wv_10 = F.grid_sample(x_10, self.grid + Dv_10/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(314)forward()\n",
      "-> Wv_11 = F.grid_sample(x_11, self.grid + Dv_11/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(316)forward()\n",
      "-> Wd_00 = F.grid_sample(x_00, self.grid + Dd_00/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(317)forward()\n",
      "-> Wd_01 = F.grid_sample(x_01, self.grid + Dd_01/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(318)forward()\n",
      "-> Wd_10 = F.grid_sample(x_10, self.grid + Dd_10/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(319)forward()\n",
      "-> Wd_11 = F.grid_sample(x_11, self.grid + Dd_11/(self.div), align_corners=False)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(321)forward()\n",
      "-> W = torch.cat((Wh_00[:,:,:,:,None], Wh_01[:,:,:,:,None], Wh_10[:,:,:,:,None], Wh_11[:,:,:,:,None],\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(322)forward()\n",
      "-> Wv_00[:,:,:,:,None], Wv_01[:,:,:,:,None], Wv_10[:,:,:,:,None], Wv_11[:,:,:,:,None],\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(323)forward()\n",
      "-> Wd_00[:,:,:,:,None], Wd_01[:,:,:,:,None], Wd_10[:,:,:,:,None], Wd_11[:,:,:,:,None]),4)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(325)forward()\n",
      "-> M = self.s_cnn(torch.cat((Wh_00, Wh_01, Wh_10, Wh_11, Wv_00, Wv_01, Wv_10, Wv_11, Wd_00, Wd_01, Wd_10, Wd_11, d_TH, d_BH, d_LV, d_RV, d_BD, d_FD, self.P, self.Q), 1))\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(326)forward()\n",
      "-> M = M.unsqueeze(4).permute(0, 4, 2, 3, 1)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(328)forward()\n",
      "-> I = torch.sum(M*W, dim = 4)\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(334)forward()\n",
      "-> return I, M\n",
      "(Pdb) \n",
      "--Return--\n",
      "> c:\\users\\mummu\\documents\\github\\view-synthesis\\custom\\network.py(334)forward()->(tensor([[[[-3...SumBackward1>), tensor([[[[[9...muteBackward>))\n",
      "-> return I, M\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py(542)__call__()\n",
      "-> for hook in self._forward_hooks.values():\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py(546)__call__()\n",
      "-> if len(self._backward_hooks) > 0:\n",
      "(Pdb) \n",
      "> c:\\users\\mummu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py(559)__call__()\n",
      "-> return result\n",
      "(Pdb) \n",
      "--Return--\n",
      "> c:\\users\\mummu\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py(559)__call__()->(tensor([[[[-3...SumBackward1>), tensor([[[[[9...muteBackward>))\n",
      "-> return result\n",
      "(Pdb) \n",
      "> <ipython-input-8-59eed2d1544a>(22)train_epoch()\n",
      "-> batch_loss = criterion1(O_view, T_view) + .5*criterion2(compute_gradient(O_view), compute_gradient(T_view)) + criterion3(M)\n",
      "(Pdb) M.shape\n",
      "torch.Size([3, 1, 192, 192, 12])\n",
      "(Pdb) M.view(-1,12).shape\n",
      "*** RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "(Pdb) M.reshape(-1,12).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([110592, 12])\n",
      "(Pdb) O_view.shape\n",
      "torch.Size([3, 3, 192, 192])\n",
      "(Pdb) torch.sum(M.reshape(-1,12),0).shape\n",
      "torch.Size([12])\n",
      "(Pdb) M.reshape(-1,12).sum().shape\n",
      "torch.Size([])\n",
      "(Pdb) M.reshape(-1,12).shape\n",
      "torch.Size([110592, 12])\n",
      "(Pdb) M.reshape(-1,12).sum(0).shape\n",
      "torch.Size([12])\n",
      "(Pdb) M.reshape(-1,12).sum(0)/M.reshape(-1,12).sum()*100\n",
      "tensor([3.0774e+00, 4.2653e-01, 3.2657e+00, 8.6508e-01, 1.4375e-03, 6.3664e-01,\n",
      "        2.3874e+00, 1.9374e-03, 3.1316e+01, 1.0963e+01, 2.9027e+01, 1.8032e+01],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "(Pdb) criterion1(O_view, T_view)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "(Pdb) criterion3(M)\n",
      "*** TypeError: forward() missing 1 required positional argument: 'target'\n",
      "(Pdb) M.reshape(-1,12).sum(0)\n",
      "tensor([3.4034e+03, 4.7171e+02, 3.6116e+03, 9.5671e+02, 1.5898e+00, 7.0408e+02,\n",
      "        2.6402e+03, 2.1426e+00, 3.4633e+04, 1.2125e+04, 3.2101e+04, 1.9942e+04],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "(Pdb) ((M.reshape(-1,12).sum(0))**2).sum()\n",
      "tensor(2.8078e+09, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "(Pdb) ((M.reshape(-1,12).mean(0))**2).sum()\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "(Pdb) (M.reshape(-1,12).mean(0)\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "(Pdb) M.reshape(-1,12).mean(0)\n",
      "tensor([3.0774e-02, 4.2653e-03, 3.2657e-02, 8.6508e-03, 1.4375e-05, 6.3664e-03,\n",
      "        2.3874e-02, 1.9374e-05, 3.1316e-01, 1.0963e-01, 2.9027e-01, 1.8032e-01],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "(Pdb) ((M.reshape(-1,12).mean(0))**2).sum()\n",
      "tensor(0.2296, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "(Pdb) torch.empty([0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913])\n",
      "*** TypeError: empty(): argument 'size' must be tuple of ints, but found element of type float at pos 1\n",
      "(Pdb) np.array([0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913])\n",
      "array([0.01913, 0.01913, 0.01913, 0.01913, 0.01913, 0.01913, 0.01913,\n",
      "       0.01913, 0.01913, 0.01913, 0.01913, 0.01913])\n",
      "(Pdb) torch.from_numpy(np.array([0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913]))\n",
      "tensor([0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191, 0.0191,\n",
      "        0.0191, 0.0191, 0.0191], dtype=torch.float64)\n",
      "(Pdb) M1 = torch.from_numpy(np.array([0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913,0.01913]))\n",
      "(Pdb) (M.reshape(-1,12).mean(0))\n",
      "tensor([3.0774e-02, 4.2653e-03, 3.2657e-02, 8.6508e-03, 1.4375e-05, 6.3664e-03,\n",
      "        2.3874e-02, 1.9374e-05, 3.1316e-01, 1.0963e-01, 2.9027e-01, 1.8032e-01],\n",
      "       device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "(Pdb) (M.reshape(-1,12).mean(0)).sum(0)\n",
      "tensor(1., device='cuda:0', grad_fn=<SumBackward1>)\n",
      "(Pdb) M1 = torch.from_numpy(np.array([1,1,1,1,1,1,1,1,1,1,1,1]/8))\n",
      "*** TypeError: unsupported operand type(s) for /: 'list' and 'int'\n",
      "(Pdb) M1 = torch.from_numpy(np.array([1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12]))\n",
      "(Pdb) M1.sum()\n",
      "tensor(1., dtype=torch.float64)\n",
      "(Pdb) (M1**2).sum()\n",
      "tensor(0.0833, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "\n",
    "writer_train = SummaryWriter(trainwr_file)\n",
    "writer_test  = SummaryWriter(testwr_file)\n",
    "\n",
    "while epoch_id < num_epochs:\n",
    "    epoch_id += 1\n",
    "    \n",
    "    try:   \n",
    "        net.train()\n",
    "        train_cost, train_psnr = train_epoch()\n",
    "        \n",
    "        net.eval()\n",
    "        test_cost, test_psnr = eval_epoch()\n",
    "        \n",
    "        print(\"Epoch %d:\" % epoch_id)     \n",
    "        print(\"Epoch {0:0}, train_cost {1:.2}, psnr {2:.2}\".format(epoch_id, train_cost, train_psnr))\n",
    "        \n",
    "        writer_train.add_scalar('psnr', train_psnr, epoch_id)\n",
    "        writer_train.add_scalar('loss', train_cost, epoch_id)\n",
    "        writer_test.add_scalar('psnr', test_psnr, epoch_id)\n",
    "        writer_test.add_scalar('loss', test_cost, epoch_id)\n",
    "        \n",
    "        torch.save({'model': net, 'epoch': epoch_id}, model_file)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print('\\nKeyboardInterrupt')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import img_diff, img_show, img_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
